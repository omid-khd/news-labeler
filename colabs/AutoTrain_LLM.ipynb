{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "JvMRbVLEJlZT"
      },
      "outputs": [],
      "source": [
        "#@title ðŸ¤— AutoTrain LLM\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload train.csv to a folder named `data/`\n",
        "#@markdown - train.csv must contain a `text` column\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can use most of the text-generation models from Hugging Face Hub\n",
        "#@markdown - add huggingface information (token) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "#@markdown - report issues / feature requests here: https://github.com/huggingface/autotrain-advanced/issues\n",
        "\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt 2>&1\n",
        "!autotrain setup --colab > setup_logs.txt\n",
        "from autotrain import __version__\n",
        "print(f'AutoTrain version: {__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/news-labeler/"
      ],
      "metadata": {
        "id": "GQSAfjQVof8R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "conf = f\"\"\"\n",
        "task: text_classification\n",
        "base_model: HooshvareLab/bert-fa-base-uncased\n",
        "project_name: news-labeler\n",
        "log: tensorboard\n",
        "backend: local\n",
        "\n",
        "data:\n",
        "    path: '/content/data'\n",
        "    train_split: train\n",
        "    valid_split: valid\n",
        "    column_mapping:\n",
        "        text_column: text\n",
        "        target_column: target\n",
        "\n",
        "params:\n",
        "  max_seq_length: 512\n",
        "  epochs: 12\n",
        "  batch_size: 32\n",
        "  lr: 2e-5\n",
        "  optimizer: adamw_torch\n",
        "  scheduler: cosine\n",
        "  warmup_ratio: 0.1\n",
        "  weight_decay: 0.01\n",
        "  gradient_accumulation: 1\n",
        "  mixed_precision: fp16\n",
        "  early_stopping_patience: 4\n",
        "  evaluation_strategy: epoch\n",
        "  save_total_limit: 3\n",
        "  load_best_model_at_end: true\n",
        "  label_smoothing: 0.1\n",
        "  class_weights: auto\n",
        "\"\"\"\n",
        "\n",
        "with open(\"config.yaml\", \"w\") as f:\n",
        "  f.write(conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca85441-2064-47cc-f798-236ff0e82c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.cli.autotrain\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mUsing AutoTrain configuration: config.yaml\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mRunning task: text_multi_class_classification\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mUsing backend: local\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m286\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: class_weights, evaluation_strategy, label_smoothing, load_best_model_at_end\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m224\u001b[0m - \u001b[1m{'data_path': '/content/data', 'model': 'HooshvareLab/bert-fa-base-uncased', 'lr': 2e-05, 'epochs': 12, 'max_seq_length': 512, 'batch_size': 32, 'warmup_ratio': 0.1, 'gradient_accumulation': 1, 'optimizer': 'adamw_torch', 'scheduler': 'cosine', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'train_split': 'train', 'valid_split': 'valid', 'text_column': 'text', 'target_column': 'target', 'logging_steps': -1, 'project_name': 'news-labeler', 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'save_total_limit': 3, 'token': None, 'push_to_hub': False, 'eval_strategy': 'epoch', 'username': None, 'log': 'tensorboard', 'early_stopping_patience': 4, 'early_stopping_threshold': 0.01}\u001b[0m\n",
            "\rCasting the dataset:   0% 0/1000 [00:00<?, ? examples/s]\rCasting the dataset: 100% 1000/1000 [00:00<00:00, 256140.70 examples/s]\n",
            "\rCasting the dataset:   0% 0/1000 [00:00<?, ? examples/s]\rCasting the dataset: 100% 1000/1000 [00:00<00:00, 262029.36 examples/s]\n",
            "\rSaving the dataset (0/1 shards):   0% 0/1000 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 1000/1000 [00:00<00:00, 330442.29 examples/s]\rSaving the dataset (1/1 shards): 100% 1000/1000 [00:00<00:00, 311960.13 examples/s]\n",
            "\rSaving the dataset (0/1 shards):   0% 0/1000 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 1000/1000 [00:00<00:00, 342280.40 examples/s]\rSaving the dataset (1/1 shards): 100% 1000/1000 [00:00<00:00, 324260.07 examples/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'fp16', '-m', 'autotrain.trainers.text_classification', '--training_config', 'news-labeler/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:55:56\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m515\u001b[0m - \u001b[1m{'data_path': 'news-labeler/autotrain-data', 'model': 'HooshvareLab/bert-fa-base-uncased', 'lr': 2e-05, 'epochs': 12, 'max_seq_length': 512, 'batch_size': 32, 'warmup_ratio': 0.1, 'gradient_accumulation': 1, 'optimizer': 'adamw_torch', 'scheduler': 'cosine', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'train_split': 'train', 'valid_split': 'validation', 'text_column': 'autotrain_text', 'target_column': 'autotrain_label', 'logging_steps': -1, 'project_name': 'news-labeler', 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'save_total_limit': 3, 'token': None, 'push_to_hub': False, 'eval_strategy': 'epoch', 'username': None, 'log': 'tensorboard', 'early_stopping_patience': 4, 'early_stopping_threshold': 0.01}\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767441369.173907   31671 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767441369.179962   31671 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767441369.195054   31671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767441369.195082   31671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767441369.195086   31671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767441369.195092   31671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:14\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:14\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:17\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mLogging steps: 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_train_begin\u001b[0m:\u001b[36m386\u001b[0m - \u001b[1mStarting to train...\u001b[0m\n",
            "  2% 6/384 [00:04<04:30,  1.40it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 2.4078, 'grad_norm': 13.950957298278809, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.1875}\u001b[0m\n",
            "{'loss': 2.4078, 'grad_norm': 13.950957298278809, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.19}\n",
            "  3% 12/384 [00:08<04:17,  1.44it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 2.2135, 'grad_norm': 9.474028587341309, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.375}\u001b[0m\n",
            "{'loss': 2.2135, 'grad_norm': 9.474028587341309, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.38}\n",
            "  5% 18/384 [00:12<04:16,  1.42it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 1.8681, 'grad_norm': 8.897629737854004, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.5625}\u001b[0m\n",
            "{'loss': 1.8681, 'grad_norm': 8.897629737854004, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.56}\n",
            "  6% 24/384 [00:17<04:11,  1.43it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 1.7228, 'grad_norm': 5.652625560760498, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.75}\u001b[0m\n",
            "{'loss': 1.7228, 'grad_norm': 5.652625560760498, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.75}\n",
            "  8% 30/384 [00:21<04:07,  1.43it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 1.5321, 'grad_norm': 3.879694938659668, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.9375}\u001b[0m\n",
            "{'loss': 1.5321, 'grad_norm': 3.879694938659668, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.94}\n",
            "  8% 32/384 [00:22<03:16,  1.79it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.30it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.04it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.65it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.47it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.42it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.38it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.36it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:02,  2.34it/s]\u001b[A\n",
            " 62% 10/16 [00:04<00:02,  2.34it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.33it/s]\u001b[A\n",
            " 75% 12/16 [00:04<00:01,  2.32it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.31it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.31it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.33it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.66it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:56:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 1.432217001914978, 'eval_f1_macro': 0.07802926321644195, 'eval_f1_micro': 0.539, 'eval_f1_weighted': 0.3835946030806219, 'eval_precision_macro': 0.15362173038229376, 'eval_precision_micro': 0.539, 'eval_precision_weighted': 0.42580382293762575, 'eval_recall_macro': 0.10428571428571429, 'eval_recall_micro': 0.539, 'eval_recall_weighted': 0.539, 'eval_accuracy': 0.539, 'eval_runtime': 6.9127, 'eval_samples_per_second': 144.661, 'eval_steps_per_second': 2.315, 'epoch': 1.0}\u001b[0m\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 1.432217001914978, 'eval_f1_macro': 0.07802926321644195, 'eval_f1_micro': 0.539, 'eval_f1_weighted': 0.3835946030806219, 'eval_precision_macro': 0.15362173038229376, 'eval_precision_micro': 0.539, 'eval_precision_weighted': 0.42580382293762575, 'eval_recall_macro': 0.10428571428571429, 'eval_recall_micro': 0.539, 'eval_recall_weighted': 0.539, 'eval_accuracy': 0.539, 'eval_runtime': 6.9127, 'eval_samples_per_second': 144.661, 'eval_steps_per_second': 2.315, 'epoch': 1.0}\n",
            "  8% 32/384 [00:29<03:16,  1.79it/s]\n",
            "100% 16/16 [00:06<00:00,  2.66it/s]\u001b[A\n",
            "  9% 36/384 [00:53<20:49,  3.59s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:57:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 1.2382, 'grad_norm': 4.201010704040527, 'learning_rate': 1.8461538461538465e-05, 'epoch': 1.125}\u001b[0m\n",
            "{'loss': 1.2382, 'grad_norm': 4.201010704040527, 'learning_rate': 1.8461538461538465e-05, 'epoch': 1.12}\n",
            " 11% 42/384 [00:57<05:58,  1.05s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:57:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 1.2536, 'grad_norm': 4.680310249328613, 'learning_rate': 1.999626881261911e-05, 'epoch': 1.3125}\u001b[0m\n",
            "{'loss': 1.2536, 'grad_norm': 4.680310249328613, 'learning_rate': 1.999626881261911e-05, 'epoch': 1.31}\n",
            " 12% 48/384 [01:02<04:12,  1.33it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:57:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 1.0447, 'grad_norm': 4.753690242767334, 'learning_rate': 1.9966436017605296e-05, 'epoch': 1.5}\u001b[0m\n",
            "{'loss': 1.0447, 'grad_norm': 4.753690242767334, 'learning_rate': 1.9966436017605296e-05, 'epoch': 1.5}\n",
            " 14% 54/384 [01:06<03:55,  1.40it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:57:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 1.0163, 'grad_norm': 5.557064056396484, 'learning_rate': 1.9906859460363307e-05, 'epoch': 1.6875}\u001b[0m\n",
            "{'loss': 1.0163, 'grad_norm': 5.557064056396484, 'learning_rate': 1.9906859460363307e-05, 'epoch': 1.69}\n",
            " 16% 60/384 [01:10<03:54,  1.38it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:57:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.721, 'grad_norm': 3.930673360824585, 'learning_rate': 1.9817716940755586e-05, 'epoch': 1.875}\u001b[0m\n",
            "{'loss': 0.721, 'grad_norm': 3.930673360824585, 'learning_rate': 1.9817716940755586e-05, 'epoch': 1.88}\n",
            " 17% 64/384 [01:12<03:02,  1.75it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.50it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.18it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.75it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.58it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.47it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.38it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.34it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:03,  2.32it/s]\u001b[A\n",
            " 62% 10/16 [00:03<00:02,  2.30it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.28it/s]\u001b[A\n",
            " 75% 12/16 [00:04<00:01,  2.27it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.27it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.27it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.30it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.62it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:57:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.7303349375724792, 'eval_f1_macro': 0.4656158153154776, 'eval_f1_micro': 0.792, 'eval_f1_weighted': 0.7576437024815574, 'eval_precision_macro': 0.574862553915038, 'eval_precision_micro': 0.792, 'eval_precision_weighted': 0.7739679606746807, 'eval_recall_macro': 0.4384791703840135, 'eval_recall_micro': 0.792, 'eval_recall_weighted': 0.792, 'eval_accuracy': 0.792, 'eval_runtime': 6.9443, 'eval_samples_per_second': 144.003, 'eval_steps_per_second': 2.304, 'epoch': 2.0}\u001b[0m\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.7303349375724792, 'eval_f1_macro': 0.4656158153154776, 'eval_f1_micro': 0.792, 'eval_f1_weighted': 0.7576437024815574, 'eval_precision_macro': 0.574862553915038, 'eval_precision_micro': 0.792, 'eval_precision_weighted': 0.7739679606746807, 'eval_recall_macro': 0.4384791703840135, 'eval_recall_micro': 0.792, 'eval_recall_weighted': 0.792, 'eval_accuracy': 0.792, 'eval_runtime': 6.9443, 'eval_samples_per_second': 144.003, 'eval_steps_per_second': 2.304, 'epoch': 2.0}\n",
            " 17% 64/384 [01:19<03:02,  1.75it/s]\n",
            "100% 16/16 [00:06<00:00,  2.62it/s]\u001b[A\n",
            " 17% 66/384 [01:49<42:53,  8.09s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:58:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.682, 'grad_norm': 6.55648946762085, 'learning_rate': 1.9699274495096712e-05, 'epoch': 2.0625}\u001b[0m\n",
            "{'loss': 0.682, 'grad_norm': 6.55648946762085, 'learning_rate': 1.9699274495096712e-05, 'epoch': 2.06}\n",
            " 19% 72/384 [01:54<08:12,  1.58s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:58:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.5584, 'grad_norm': 6.844950199127197, 'learning_rate': 1.9551885602196482e-05, 'epoch': 2.25}\u001b[0m\n",
            "{'loss': 0.5584, 'grad_norm': 6.844950199127197, 'learning_rate': 1.9551885602196482e-05, 'epoch': 2.25}\n",
            " 20% 78/384 [01:58<04:11,  1.22it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:58:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.6111, 'grad_norm': 5.45509147644043, 'learning_rate': 1.9375990128440205e-05, 'epoch': 2.4375}\u001b[0m\n",
            "{'loss': 0.6111, 'grad_norm': 5.45509147644043, 'learning_rate': 1.9375990128440205e-05, 'epoch': 2.44}\n",
            " 22% 84/384 [02:02<03:38,  1.37it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:58:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.4675, 'grad_norm': 9.031580924987793, 'learning_rate': 1.917211301505453e-05, 'epoch': 2.625}\u001b[0m\n",
            "{'loss': 0.4675, 'grad_norm': 9.031580924987793, 'learning_rate': 1.917211301505453e-05, 'epoch': 2.62}\n",
            " 23% 90/384 [02:07<03:32,  1.39it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:58:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.4941, 'grad_norm': 7.199426651000977, 'learning_rate': 1.8940862711476515e-05, 'epoch': 2.8125}\u001b[0m\n",
            "{'loss': 0.4941, 'grad_norm': 7.199426651000977, 'learning_rate': 1.8940862711476515e-05, 'epoch': 2.81}\n",
            " 25% 96/384 [02:10<02:46,  1.73it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:58:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.5374, 'grad_norm': 6.377241611480713, 'learning_rate': 1.8682929359501338e-05, 'epoch': 3.0}\u001b[0m\n",
            "{'loss': 0.5374, 'grad_norm': 6.377241611480713, 'learning_rate': 1.8682929359501338e-05, 'epoch': 3.0}\n",
            " 25% 96/384 [02:10<02:46,  1.73it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.50it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.17it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.76it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.57it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.46it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.38it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.33it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:03,  2.30it/s]\u001b[A\n",
            " 62% 10/16 [00:04<00:02,  2.28it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.27it/s]\u001b[A\n",
            " 75% 12/16 [00:04<00:01,  2.26it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.25it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.26it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.27it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.59it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:58:36\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.5203877091407776, 'eval_f1_macro': 0.5918602165552607, 'eval_f1_micro': 0.867, 'eval_f1_weighted': 0.8566063021995884, 'eval_precision_macro': 0.6851936163391132, 'eval_precision_micro': 0.867, 'eval_precision_weighted': 0.8624758849596151, 'eval_recall_macro': 0.5622760846491874, 'eval_recall_micro': 0.867, 'eval_recall_weighted': 0.867, 'eval_accuracy': 0.867, 'eval_runtime': 6.9841, 'eval_samples_per_second': 143.183, 'eval_steps_per_second': 2.291, 'epoch': 3.0}\u001b[0m\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.5203877091407776, 'eval_f1_macro': 0.5918602165552607, 'eval_f1_micro': 0.867, 'eval_f1_weighted': 0.8566063021995884, 'eval_precision_macro': 0.6851936163391132, 'eval_precision_micro': 0.867, 'eval_precision_weighted': 0.8624758849596151, 'eval_recall_macro': 0.5622760846491874, 'eval_recall_micro': 0.867, 'eval_recall_weighted': 0.867, 'eval_accuracy': 0.867, 'eval_runtime': 6.9841, 'eval_samples_per_second': 143.183, 'eval_steps_per_second': 2.291, 'epoch': 3.0}\n",
            " 25% 96/384 [02:17<02:46,  1.73it/s]\n",
            "100% 16/16 [00:06<00:00,  2.59it/s]\u001b[A\n",
            " 27% 102/384 [02:47<11:00,  2.34s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:59:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.3577, 'grad_norm': 3.111478567123413, 'learning_rate': 1.8399082733627967e-05, 'epoch': 3.1875}\u001b[0m\n",
            "{'loss': 0.3577, 'grad_norm': 3.111478567123413, 'learning_rate': 1.8399082733627967e-05, 'epoch': 3.19}\n",
            " 28% 108/384 [02:52<04:10,  1.10it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:59:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.319, 'grad_norm': 2.4075236320495605, 'learning_rate': 1.8090169943749477e-05, 'epoch': 3.375}\u001b[0m\n",
            "{'loss': 0.319, 'grad_norm': 2.4075236320495605, 'learning_rate': 1.8090169943749477e-05, 'epoch': 3.38}\n",
            " 30% 114/384 [02:56<03:22,  1.33it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:59:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.3922, 'grad_norm': 3.624274969100952, 'learning_rate': 1.77571129070442e-05, 'epoch': 3.5625}\u001b[0m\n",
            "{'loss': 0.3922, 'grad_norm': 3.624274969100952, 'learning_rate': 1.77571129070442e-05, 'epoch': 3.56}\n",
            " 31% 120/384 [03:00<03:12,  1.37it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:59:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.3249, 'grad_norm': 5.940813064575195, 'learning_rate': 1.740090559661252e-05, 'epoch': 3.75}\u001b[0m\n",
            "{'loss': 0.3249, 'grad_norm': 5.940813064575195, 'learning_rate': 1.740090559661252e-05, 'epoch': 3.75}\n",
            " 33% 126/384 [03:05<03:08,  1.37it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:59:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.3079, 'grad_norm': 6.021637439727783, 'learning_rate': 1.7022611075070476e-05, 'epoch': 3.9375}\u001b[0m\n",
            "{'loss': 0.3079, 'grad_norm': 6.021637439727783, 'learning_rate': 1.7022611075070476e-05, 'epoch': 3.94}\n",
            " 33% 128/384 [03:06<02:28,  1.72it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.45it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.15it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.73it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.50it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.35it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.26it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.21it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:03,  2.18it/s]\u001b[A\n",
            " 62% 10/16 [00:04<00:02,  2.20it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.21it/s]\u001b[A\n",
            " 75% 12/16 [00:05<00:01,  2.21it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.21it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.22it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.25it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.56it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:59:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.4802432358264923, 'eval_f1_macro': 0.6047145688120479, 'eval_f1_micro': 0.878, 'eval_f1_weighted': 0.8697946616253379, 'eval_precision_macro': 0.6627158646203969, 'eval_precision_micro': 0.878, 'eval_precision_weighted': 0.8681472939896276, 'eval_recall_macro': 0.5835224158690407, 'eval_recall_micro': 0.878, 'eval_recall_weighted': 0.878, 'eval_accuracy': 0.878, 'eval_runtime': 7.1702, 'eval_samples_per_second': 139.466, 'eval_steps_per_second': 2.231, 'epoch': 4.0}\u001b[0m\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.4802432358264923, 'eval_f1_macro': 0.6047145688120479, 'eval_f1_micro': 0.878, 'eval_f1_weighted': 0.8697946616253379, 'eval_precision_macro': 0.6627158646203969, 'eval_precision_micro': 0.878, 'eval_precision_weighted': 0.8681472939896276, 'eval_recall_macro': 0.5835224158690407, 'eval_recall_micro': 0.878, 'eval_recall_weighted': 0.878, 'eval_accuracy': 0.878, 'eval_runtime': 7.1702, 'eval_samples_per_second': 139.466, 'eval_steps_per_second': 2.231, 'epoch': 4.0}\n",
            " 33% 128/384 [03:13<02:28,  1.72it/s]\n",
            "100% 16/16 [00:06<00:00,  2.56it/s]\u001b[A\n",
            " 34% 132/384 [03:37<15:09,  3.61s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 11:59:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.3528, 'grad_norm': 5.611186504364014, 'learning_rate': 1.662335832195308e-05, 'epoch': 4.125}\u001b[0m\n",
            "{'loss': 0.3528, 'grad_norm': 5.611186504364014, 'learning_rate': 1.662335832195308e-05, 'epoch': 4.12}\n",
            " 36% 138/384 [03:41<04:21,  1.06s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.3008, 'grad_norm': 6.146496295928955, 'learning_rate': 1.6204338864395683e-05, 'epoch': 4.3125}\u001b[0m\n",
            "{'loss': 0.3008, 'grad_norm': 6.146496295928955, 'learning_rate': 1.6204338864395683e-05, 'epoch': 4.31}\n",
            " 38% 144/384 [03:46<03:06,  1.29it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.2194, 'grad_norm': 10.29651927947998, 'learning_rate': 1.5766803221148676e-05, 'epoch': 4.5}\u001b[0m\n",
            "{'loss': 0.2194, 'grad_norm': 10.29651927947998, 'learning_rate': 1.5766803221148676e-05, 'epoch': 4.5}\n",
            " 39% 150/384 [03:50<02:53,  1.35it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1732, 'grad_norm': 1.9296717643737793, 'learning_rate': 1.5312057170538033e-05, 'epoch': 4.6875}\u001b[0m\n",
            "{'loss': 0.1732, 'grad_norm': 1.9296717643737793, 'learning_rate': 1.5312057170538033e-05, 'epoch': 4.69}\n",
            " 41% 156/384 [03:54<02:46,  1.37it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:13\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1432, 'grad_norm': 2.063044309616089, 'learning_rate': 1.4841457853509606e-05, 'epoch': 4.875}\u001b[0m\n",
            "{'loss': 0.1432, 'grad_norm': 2.063044309616089, 'learning_rate': 1.4841457853509606e-05, 'epoch': 4.88}\n",
            " 42% 160/384 [03:57<02:10,  1.71it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.39it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.10it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.70it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.52it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.41it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.34it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.29it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:03,  2.27it/s]\u001b[A\n",
            " 62% 10/16 [00:04<00:02,  2.25it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.24it/s]\u001b[A\n",
            " 75% 12/16 [00:04<00:01,  2.22it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.22it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.22it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.24it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.54it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.5194182395935059, 'eval_f1_macro': 0.6144167456401785, 'eval_f1_micro': 0.873, 'eval_f1_weighted': 0.8672231938760911, 'eval_precision_macro': 0.6838870490088491, 'eval_precision_micro': 0.873, 'eval_precision_weighted': 0.8686407075131274, 'eval_recall_macro': 0.5854027577966718, 'eval_recall_micro': 0.873, 'eval_recall_weighted': 0.873, 'eval_accuracy': 0.873, 'eval_runtime': 7.1205, 'eval_samples_per_second': 140.44, 'eval_steps_per_second': 2.247, 'epoch': 5.0}\u001b[0m\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5194182395935059, 'eval_f1_macro': 0.6144167456401785, 'eval_f1_micro': 0.873, 'eval_f1_weighted': 0.8672231938760911, 'eval_precision_macro': 0.6838870490088491, 'eval_precision_micro': 0.873, 'eval_precision_weighted': 0.8686407075131274, 'eval_recall_macro': 0.5854027577966718, 'eval_recall_micro': 0.873, 'eval_recall_weighted': 0.873, 'eval_accuracy': 0.873, 'eval_runtime': 7.1205, 'eval_samples_per_second': 140.44, 'eval_steps_per_second': 2.247, 'epoch': 5.0}\n",
            " 42% 160/384 [04:04<02:10,  1.71it/s]\n",
            "100% 16/16 [00:06<00:00,  2.54it/s]\u001b[A\n",
            " 42% 162/384 [04:25<23:16,  6.29s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.2148, 'grad_norm': 3.3311522006988525, 'learning_rate': 1.4356409723387092e-05, 'epoch': 5.0625}\u001b[0m\n",
            "{'loss': 0.2148, 'grad_norm': 3.3311522006988525, 'learning_rate': 1.4356409723387092e-05, 'epoch': 5.06}\n",
            " 44% 168/384 [04:30<04:58,  1.38s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1656, 'grad_norm': 4.05124044418335, 'learning_rate': 1.3858360354431355e-05, 'epoch': 5.25}\u001b[0m\n",
            "{'loss': 0.1656, 'grad_norm': 4.05124044418335, 'learning_rate': 1.3858360354431355e-05, 'epoch': 5.25}\n",
            " 45% 174/384 [04:34<02:51,  1.22it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1473, 'grad_norm': 3.162584066390991, 'learning_rate': 1.3348796121709862e-05, 'epoch': 5.4375}\u001b[0m\n",
            "{'loss': 0.1473, 'grad_norm': 3.162584066390991, 'learning_rate': 1.3348796121709862e-05, 'epoch': 5.44}\n",
            " 47% 180/384 [04:38<02:30,  1.35it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:00:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1377, 'grad_norm': 1.4086464643478394, 'learning_rate': 1.28292377651693e-05, 'epoch': 5.625}\u001b[0m\n",
            "{'loss': 0.1377, 'grad_norm': 1.4086464643478394, 'learning_rate': 1.28292377651693e-05, 'epoch': 5.62}\n",
            " 48% 186/384 [04:43<02:26,  1.35it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:01:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1589, 'grad_norm': 1.616808295249939, 'learning_rate': 1.2301235851149867e-05, 'epoch': 5.8125}\u001b[0m\n",
            "{'loss': 0.1589, 'grad_norm': 1.616808295249939, 'learning_rate': 1.2301235851149867e-05, 'epoch': 5.81}\n",
            " 50% 192/384 [04:47<01:53,  1.70it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:01:05\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1662, 'grad_norm': 21.132862091064453, 'learning_rate': 1.1766366144885877e-05, 'epoch': 6.0}\u001b[0m\n",
            "{'loss': 0.1662, 'grad_norm': 21.132862091064453, 'learning_rate': 1.1766366144885877e-05, 'epoch': 6.0}\n",
            " 50% 192/384 [04:47<01:53,  1.70it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.33it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.07it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.67it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.49it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.39it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.29it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.26it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:03,  2.24it/s]\u001b[A\n",
            " 62% 10/16 [00:04<00:02,  2.22it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.20it/s]\u001b[A\n",
            " 75% 12/16 [00:05<00:01,  2.19it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.19it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.18it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.21it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.53it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:01:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.5188961029052734, 'eval_f1_macro': 0.6144173155235673, 'eval_f1_micro': 0.873, 'eval_f1_weighted': 0.8678999304772763, 'eval_precision_macro': 0.6934048578469317, 'eval_precision_micro': 0.873, 'eval_precision_weighted': 0.8720014038477858, 'eval_recall_macro': 0.5809789879974443, 'eval_recall_micro': 0.873, 'eval_recall_weighted': 0.873, 'eval_accuracy': 0.873, 'eval_runtime': 7.2081, 'eval_samples_per_second': 138.733, 'eval_steps_per_second': 2.22, 'epoch': 6.0}\u001b[0m\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5188961029052734, 'eval_f1_macro': 0.6144173155235673, 'eval_f1_micro': 0.873, 'eval_f1_weighted': 0.8678999304772763, 'eval_precision_macro': 0.6934048578469317, 'eval_precision_micro': 0.873, 'eval_precision_weighted': 0.8720014038477858, 'eval_recall_macro': 0.5809789879974443, 'eval_recall_micro': 0.873, 'eval_recall_weighted': 0.873, 'eval_accuracy': 0.873, 'eval_runtime': 7.2081, 'eval_samples_per_second': 138.733, 'eval_steps_per_second': 2.22, 'epoch': 6.0}\n",
            " 50% 192/384 [04:54<01:53,  1.70it/s]\n",
            "100% 16/16 [00:06<00:00,  2.53it/s]\u001b[A\n",
            " 52% 198/384 [05:25<07:30,  2.42s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:01:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1114, 'grad_norm': 12.414809226989746, 'learning_rate': 1.1226224907802986e-05, 'epoch': 6.1875}\u001b[0m\n",
            "{'loss': 0.1114, 'grad_norm': 12.414809226989746, 'learning_rate': 1.1226224907802986e-05, 'epoch': 6.19}\n",
            " 53% 204/384 [05:29<02:47,  1.08it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:01:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1074, 'grad_norm': 2.0285451412200928, 'learning_rate': 1.0682424133646712e-05, 'epoch': 6.375}\u001b[0m\n",
            "{'loss': 0.1074, 'grad_norm': 2.0285451412200928, 'learning_rate': 1.0682424133646712e-05, 'epoch': 6.38}\n",
            " 55% 210/384 [05:34<02:11,  1.32it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:01:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.112, 'grad_norm': 0.7298269271850586, 'learning_rate': 1.013658673765951e-05, 'epoch': 6.5625}\u001b[0m\n",
            "{'loss': 0.112, 'grad_norm': 0.7298269271850586, 'learning_rate': 1.013658673765951e-05, 'epoch': 6.56}\n",
            " 56% 216/384 [05:38<02:04,  1.35it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:01:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.1101, 'grad_norm': 1.8285746574401855, 'learning_rate': 9.590341713163858e-06, 'epoch': 6.75}\u001b[0m\n",
            "{'loss': 0.1101, 'grad_norm': 1.8285746574401855, 'learning_rate': 9.590341713163858e-06, 'epoch': 6.75}\n",
            " 58% 222/384 [05:43<02:00,  1.34it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:02:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.0638, 'grad_norm': 1.2361419200897217, 'learning_rate': 9.0453192700059e-06, 'epoch': 6.9375}\u001b[0m\n",
            "{'loss': 0.0638, 'grad_norm': 1.2361419200897217, 'learning_rate': 9.0453192700059e-06, 'epoch': 6.94}\n",
            " 58% 224/384 [05:44<01:34,  1.69it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.31it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.06it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.67it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.49it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.39it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.32it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.27it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:03,  2.25it/s]\u001b[A\n",
            " 62% 10/16 [00:04<00:02,  2.23it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.22it/s]\u001b[A\n",
            " 75% 12/16 [00:05<00:01,  2.20it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.20it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.20it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.22it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.51it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:02:09\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.5524673461914062, 'eval_f1_macro': 0.6303890584690021, 'eval_f1_micro': 0.866, 'eval_f1_weighted': 0.8628752130329075, 'eval_precision_macro': 0.7201797941344054, 'eval_precision_micro': 0.866, 'eval_precision_weighted': 0.8715290054264229, 'eval_recall_macro': 0.5902714916698374, 'eval_recall_micro': 0.866, 'eval_recall_weighted': 0.866, 'eval_accuracy': 0.866, 'eval_runtime': 7.1751, 'eval_samples_per_second': 139.372, 'eval_steps_per_second': 2.23, 'epoch': 7.0}\u001b[0m\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5524673461914062, 'eval_f1_macro': 0.6303890584690021, 'eval_f1_micro': 0.866, 'eval_f1_weighted': 0.8628752130329075, 'eval_precision_macro': 0.7201797941344054, 'eval_precision_micro': 0.866, 'eval_precision_weighted': 0.8715290054264229, 'eval_recall_macro': 0.5902714916698374, 'eval_recall_micro': 0.866, 'eval_recall_weighted': 0.866, 'eval_accuracy': 0.866, 'eval_runtime': 7.1751, 'eval_samples_per_second': 139.372, 'eval_steps_per_second': 2.23, 'epoch': 7.0}\n",
            " 58% 224/384 [05:51<01:34,  1.69it/s]\n",
            "100% 16/16 [00:06<00:00,  2.51it/s]\u001b[A\n",
            " 59% 228/384 [06:25<12:04,  4.65s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:02:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.0467, 'grad_norm': 1.5409562587738037, 'learning_rate': 8.503145969368562e-06, 'epoch': 7.125}\u001b[0m\n",
            "{'loss': 0.0467, 'grad_norm': 1.5409562587738037, 'learning_rate': 8.503145969368562e-06, 'epoch': 7.12}\n",
            " 61% 234/384 [06:29<02:59,  1.20s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:02:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.0555, 'grad_norm': 0.7413148880004883, 'learning_rate': 7.965439869473664e-06, 'epoch': 7.3125}\u001b[0m\n",
            "{'loss': 0.0555, 'grad_norm': 0.7413148880004883, 'learning_rate': 7.965439869473664e-06, 'epoch': 7.31}\n",
            " 62% 240/384 [06:34<01:52,  1.27it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:02:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.075, 'grad_norm': 3.8898935317993164, 'learning_rate': 7.433805696660267e-06, 'epoch': 7.5}\u001b[0m\n",
            "{'loss': 0.075, 'grad_norm': 3.8898935317993164, 'learning_rate': 7.433805696660267e-06, 'epoch': 7.5}\n",
            " 64% 246/384 [06:38<01:41,  1.36it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:02:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.0505, 'grad_norm': 5.073936939239502, 'learning_rate': 6.909830056250527e-06, 'epoch': 7.6875}\u001b[0m\n",
            "{'loss': 0.0505, 'grad_norm': 5.073936939239502, 'learning_rate': 6.909830056250527e-06, 'epoch': 7.69}\n",
            " 66% 252/384 [06:43<01:37,  1.35it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:03:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'loss': 0.0908, 'grad_norm': 3.198021173477173, 'learning_rate': 6.395076697495854e-06, 'epoch': 7.875}\u001b[0m\n",
            "{'loss': 0.0908, 'grad_norm': 3.198021173477173, 'learning_rate': 6.395076697495854e-06, 'epoch': 7.88}\n",
            " 67% 256/384 [06:45<01:15,  1.70it/s]\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 2/16 [00:00<00:03,  4.40it/s]\u001b[A\n",
            " 19% 3/16 [00:00<00:04,  3.10it/s]\u001b[A\n",
            " 25% 4/16 [00:01<00:04,  2.68it/s]\u001b[A\n",
            " 31% 5/16 [00:01<00:04,  2.50it/s]\u001b[A\n",
            " 38% 6/16 [00:02<00:04,  2.39it/s]\u001b[A\n",
            " 44% 7/16 [00:02<00:03,  2.31it/s]\u001b[A\n",
            " 50% 8/16 [00:03<00:03,  2.27it/s]\u001b[A\n",
            " 56% 9/16 [00:03<00:03,  2.25it/s]\u001b[A\n",
            " 62% 10/16 [00:04<00:02,  2.21it/s]\u001b[A\n",
            " 69% 11/16 [00:04<00:02,  2.20it/s]\u001b[A\n",
            " 75% 12/16 [00:05<00:01,  2.19it/s]\u001b[A\n",
            " 81% 13/16 [00:05<00:01,  2.20it/s]\u001b[A\n",
            " 88% 14/16 [00:05<00:00,  2.20it/s]\u001b[A\n",
            " 94% 15/16 [00:06<00:00,  2.22it/s]\u001b[A\n",
            "100% 16/16 [00:06<00:00,  2.53it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:03:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.578883171081543, 'eval_f1_macro': 0.6169353930608181, 'eval_f1_micro': 0.862, 'eval_f1_weighted': 0.8586418429672151, 'eval_precision_macro': 0.6969929901191715, 'eval_precision_micro': 0.862, 'eval_precision_weighted': 0.8646162970713789, 'eval_recall_macro': 0.5818741782833725, 'eval_recall_micro': 0.862, 'eval_recall_weighted': 0.862, 'eval_accuracy': 0.862, 'eval_runtime': 7.1948, 'eval_samples_per_second': 138.989, 'eval_steps_per_second': 2.224, 'epoch': 8.0}\u001b[0m\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.578883171081543, 'eval_f1_macro': 0.6169353930608181, 'eval_f1_micro': 0.862, 'eval_f1_weighted': 0.8586418429672151, 'eval_precision_macro': 0.6969929901191715, 'eval_precision_micro': 0.862, 'eval_precision_weighted': 0.8646162970713789, 'eval_recall_macro': 0.5818741782833725, 'eval_recall_micro': 0.862, 'eval_recall_weighted': 0.862, 'eval_accuracy': 0.862, 'eval_runtime': 7.1948, 'eval_samples_per_second': 138.989, 'eval_steps_per_second': 2.224, 'epoch': 8.0}\n",
            " 67% 256/384 [06:52<01:15,  1.70it/s]\n",
            "100% 16/16 [00:06<00:00,  2.53it/s]\u001b[A\n",
            "                                   \u001b[A\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:03:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'train_runtime': 439.6016, 'train_samples_per_second': 27.297, 'train_steps_per_second': 0.874, 'train_loss': 0.5415102664846927, 'epoch': 8.0}\u001b[0m\n",
            "{'train_runtime': 439.6016, 'train_samples_per_second': 27.297, 'train_steps_per_second': 0.874, 'train_loss': 0.5415102664846927, 'epoch': 8.0}\n",
            " 67% 256/384 [07:19<03:39,  1.72s/it]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:03:37\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n",
            "100% 16/16 [00:06<00:00,  2.59it/s]/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:03:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1m{'eval_loss': 0.4802432358264923, 'eval_f1_macro': 0.6047145688120479, 'eval_f1_micro': 0.878, 'eval_f1_weighted': 0.8697946616253379, 'eval_precision_macro': 0.6627158646203969, 'eval_precision_micro': 0.878, 'eval_precision_weighted': 0.8681472939896276, 'eval_recall_macro': 0.5835224158690407, 'eval_recall_micro': 0.878, 'eval_recall_weighted': 0.878, 'eval_accuracy': 0.878, 'eval_runtime': 7.0597, 'eval_samples_per_second': 141.65, 'eval_steps_per_second': 2.266, 'epoch': 8.0}\u001b[0m\n",
            "100% 16/16 [00:06<00:00,  2.47it/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2026-01-03 12:03:59\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mJob ID: 31640\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain --config config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/news-labeler.zip /content/news-labeler\n"
      ],
      "metadata": {
        "id": "lbH0cBUKwg4m",
        "outputId": "e77964db-b7ea-499d-f686-b1daa72f7b72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/news-labeler/ (stored 0%)\n",
            "  adding: content/news-labeler/model.safetensors (deflated 8%)\n",
            "  adding: content/news-labeler/checkpoint-224/ (stored 0%)\n",
            "  adding: content/news-labeler/checkpoint-224/model.safetensors (deflated 8%)\n",
            "  adding: content/news-labeler/checkpoint-224/scheduler.pt (deflated 61%)\n",
            "  adding: content/news-labeler/checkpoint-224/trainer_state.json (deflated 76%)\n",
            "  adding: content/news-labeler/checkpoint-224/rng_state.pth (deflated 26%)\n",
            "  adding: content/news-labeler/checkpoint-224/config.json (deflated 54%)\n",
            "  adding: content/news-labeler/checkpoint-224/optimizer.pt"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}